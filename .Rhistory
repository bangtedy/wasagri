install.packages("cleanrmd")
install.packages("highr")
remotes::install_github("EllaKaye/distilltools")
install.packages("remotes")
remotes::install_github("EllaKaye/distilltools")
X <- c(-6,-5,2,4,7,15,17,19,13,9,4,0,10,10,14,17,22,24,26,27,22,19,14,12,1,0,5,9,14,20,23,24,21,14,9,4)
Y <- c(91,89,76,52,42,36,37,39,26,27,68,92,13,21,42,64,79,81,86,92,36,23,13,41,23,82,40,45,39,43,50,95,64,78,9,12)
Z <- c(rep('Davos',12),rep('Polenca',12),rep('Basel',12))
cor(X[Z=='Davos'],Y[Z=='Davos'])
cor(X[Z=='Basel'],Y[Z=='Basel'])
cor(X[Z=='Polenca'],Y[Z=='Polenca'])
plot(X[Z=='Davos'],Y[Z=='Davos'])
plot(X[Z=='Basel'],Y[Z=='Basel'], add=TRUE)
plot(X[Z=='Polenca'],Y[Z=='Polenca'], add=TRUE)
X <- c(-6,-5,2,4,7,15,17,19,13,9,4,0,10,10,14,17,22,24,26,27,22,19,14,12,1,0,5,9,14,20,23,24,21,14,9,4)
Y <- c(91,89,76,52,42,36,37,39,26,27,68,92,13,21,42,64,79,81,86,92,36,23,13,41,23,82,40,45,39,43,50,95,64,78,9,12)
P <- c('Davos', 'Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos',
'Polenca','Polenca','Polenca','Polenca','Polenca','Polenca','Polenca','Polenca','Polenca',
'Polenca','Polenca','Polenca', 'Basel','Basel','Basel','Basel','Basel','Basel','Basel',
'Basel','Basel','Basel','Basel','Basel')
df <- data.frame(P,X,Y)
require(ggplot2)
p <- ggplot(df, aes(X,Y))
p + geom_point(aes(colour = factor(P)))
p + geom_point(aes(pch = factor(P)))
p + geom_point(aes(pch = city(P)))
p + geom_point(aes(pch = factor(P)))
p + geom_point(aes(pch = 3:5, factor(P)))
Suhu <- c(-6,-5,2,4,7,15,17,19,13,9,4,0,10,10,14,17,22,24,26,27,22,19,14,12,1,0,5,9,14,20,23,24,21,14,9,4)
TH <- c(91,89,76,52,42,36,37,39,26,27,68,92,13,21,42,64,79,81,86,92,36,23,13,41,23,82,40,45,39,43,50,95,64,78,9,12)
Kota <- c('Davos', 'Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos',
'Polenca','Polenca','Polenca','Polenca','Polenca','Polenca','Polenca','Polenca','Polenca',
'Polenca','Polenca','Polenca', 'Basel','Basel','Basel','Basel','Basel','Basel','Basel',
'Basel','Basel','Basel','Basel','Basel')
df <- data.frame(P,X,Y)
df <- data.frame(Kota,X,Y)
df <- data.frame(Kota,Suhu,TH)
require(ggplot2)
p <- ggplot(df, aes(Suhu,TH))
p + geom_point(aes(pch = factor(Kota)))
plot(Suhu[Kota=='Davos'],TH[Kota=='Davos'])
par(new=TRUE)
plot(Suhu[Kota=='Basel'],TH[Kota=='Basel'])
Suhu <- c(-6,-5,2,4,7,15,17,19,13,9,4,0,10,10,14,17,22,24,26,27,22,19,14,12,1,0,5,9,14,20,23,24,21,14,9,4)
TH <- c(91,89,76,52,42,36,37,39,26,27,68,92,13,21,42,64,79,81,86,92,36,23,13,41,23,82,40,45,39,43,50,95,64,78,9,12)
Kota <- c('Davos', 'Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos','Davos',
'Polenca','Polenca','Polenca','Polenca','Polenca','Polenca','Polenca','Polenca','Polenca',
'Polenca','Polenca','Polenca', 'Basel','Basel','Basel','Basel','Basel','Basel','Basel',
'Basel','Basel','Basel','Basel','Basel')
df <- data.frame(Kota,Suhu,TH)
require(ggplot2)
library(ggrepel)
ggplot(df, aes(Suhu, TH))+
geom_point() +
geom_text_repel(aes(label=Kota))
library(tswge)
install.packages(c("cli", "forecast", "purrr", "rbibutils", "survival", "svglite", "timeDate", "writexl", "yfR"))
source("http://datayyy.com/cfe.R")
source("http://datayyy.com/cfe/week1.R")
load("w1.RData")
.cf()
.c1
.C1EXPLAIN1
8
.C1EXPLAIN18
.C1EXPLAIN8
.C1EXPLAIN7
#Code 2.2 Cobweb plots for linear difference equations (lin_cob.R)
rm(list=ls(all=TRUE)) #clear values between runs
##Define model equation
f.x<- function(x,r,b) {r*x+b}
##Formulate cobweb iteration loop
cobweb<- function(x_initial,nstep,r){
iterations<-nstep #number of iterations
x<- x_initial #initial condition for x
y<- f.x(x,r,b) #subequent value of x
segments(x,0,x,y,lty=1,lwd=2)
for(i in 1:iterations){
points(x,y,pch=19,cex=1.5) #iterated points along model equation
segments(x,y,y,y,lty=1,lwd=2) #segments from model to reflection line
x<- y
y<- f.x(x,r,b)
segments(x,x,x,y,lty=1,lwd=2) #segments from reflection line to model
}
} # end cobweb function
## Set parameters and initial condition for cobweb function
r<- -0.5 #stability parameter
b<-0.5
x_initial<-10 #initial condition
nstep<-25 #number of iterations
## Set axis limits for cobweb plots
x_upper<-x_initial+400 #set upper limit if solution explodes
x_upper_cycle<-x_initial+4 #set upper limit for two-cycle
if(r>0&&r<1){ #solution decays monotonically
plot(0,0,type="n",xlim=c(0,x_initial),ylim=c(0,x_initial),xlab="x(t)",
ylab="x(t+1)",cex.lab=1.5,cex.axis=1.2)
#model equation
curve(f.x(x,r,b),from = 0, to =x_initial,lty=1,lwd=2,col="blue",add=T)
#reflection line
segments(0,0,x_initial,x_initial,lty=1,lwd=2,col="red")}
if(r>-1&&r<0){ #solution decays cyclically
plot(0,0,type="n",xlim=c((-x_initial),x_initial),
ylim=c((-x_initial),x_initial),xlab="x(t)",
ylab="x(t+1)",cex.lab=1.5,cex.axis=1.2)
curve(f.x(x,r,b),from = (-x_initial), to =x_initial,lty=1,lwd=2,col="blue",add=T)
segments((-x_initial),(-x_initial),x_initial,x_initial,lty=1,lwd=2,col="red")}
if(r>1){ #solution explodes monotonically
plot(0,0,type="n",xlim=c(x_initial,x_upper),ylim=c(x_initial,x_upper),
xlab="x(t)",ylab="x(t+1)",cex.lab=1.5,cex.axis=1.2)
curve(f.x(x,r,b),from = x_initial, to =x_upper,lty=1,lwd=2,col="blue",add=T)
segments(x_initial,x_initial,x_upper,x_upper,lty=1,lwd=2,col="red")}
if(r<=(-1)){ #solution explodes cyclically
plot(0,0,type="n",xlim=c((-x_upper_cycle),x_upper_cycle),ylim=c((-x_upper_cycle),
x_upper_cycle),xlab="x(t)",ylab="x(t+1)",cex.lab=1.5,cex.axis=1.2)
curve(f.x(x,r,b),from =(-x_upper_cycle),to =x_upper_cycle,lty=1,lwd=2,col="blue",add=T)
segments((-x_upper_cycle),(-x_upper_cycle),x_upper_cycle,x_upper_cycle,lty=1,
lwd=2,col="red")}
cobweb(x_initial,nstep,r) #call for cobweb function
#Code 2.2 Cobweb plots for linear difference equations (lin_cob.R)
rm(list=ls(all=TRUE)) #clear values between runs
install.packages(c("curl", "parallelly", "rbibutils", "stringi", "timechange"))
q()
source("~/cfe.R", encoding = 'UTF-8')
load("~/w1.RData")
install.packages(c("bookdown", "dbplyr", "evaluate", "gmp", "RcppArmadillo", "Rmpfr"))
source("~/week1.txt", encoding = 'UTF-8')
.c1(.uu)
.cf()
.c2()
.C2EXPLAIN1
.c1()
.C1EXPLAIN2
.C1EXPLAIN10
q()
set.seed(42)
y.wn <- arima.sim(n=100,list(order=c(0,0,0)))
plot(y.wn)
set.seed(42)
y.rw <- ts(cumsum(rnorm(100)))
plot(y.rw)
set.seed(42)
y.rwd <- ts(cumsum(rnorm(100,mean=0.25)))
plot(y.rwd)
require(forecast)
ndiffs(y.rw)
## Set maximum lag to be considered
lag.max <- 5
## Extract the length of the series, T
T <- length(y.wn)
## Extract the values of rho computed by acf()
rho.hat <- acf(y.wn,lag.max=lag.max,plot=FALSE)$acf
## Determine how many lags there are
K <- length(rho.hat)
## Compute the variance of each rho value
var.rho.hat <- c(NA,1/T,(1+cumsum(2*rho.hat[2:(K-1)]^2))/T)
## Compute the Ljung-Box Q statistics
Q.lb <- c(NA,T*(T+2)*cumsum((rho.hat^2/(T-0:lag.max))[-1]))
## Compute Bartlett's Z statistic
Z.Bartlett <- c(NA,(rho.hat/sqrt(var.rho.hat))[-1])
## Compute the critical values for the Q statistics
Q.crit <- c(NA,qchisq(0.95,df=1:(K-1)))
Box.test(y.wn,lag=2,type="Ljung-Box")$statistic
lag.max <- 5
acf(y.rw,lag.max=lag.max,main="")
## Create a vector for storing the t-statistics
t2 <- numeric()
## Conduct 1000 Monte Carlo replications
for(i in 1:1000) {
## Generate iid data for x and y and let y=x+epsilon (coefficient on
## x is 1)
x <- rnorm(100)
y <- x + rnorm(100)
## Fit a linear model regressing y on x
model <- lm(y~x)
## Compute the t-statistic for a test of the hypothesis beta2=1 using
## the OLS asymptotics
t2[i] <- (coef(model)[2]-1)/sqrt(diag(vcov(model)))[2]
}
t2 <- sort(t2)
d <- density(t2,bw="nrd")
ylim <- range(c(d$y,dt(t2,df=100)))
plot(d,xlab="$t$-statistic",ylim=ylim,main="")
lines(t2,dt(t2,df=100),col=1,lty=2)
legend("topleft",c("Empirical Distribution","Student-$t$ Distribution"),
lty=1:2,
col=c(1,1),
bty="n")
## Plot the empirical density of the vector of t-statistics and the
## (incorrect) asymptotic distribution
d <- density(t2,bw="nrd")
ylim <- range(c(d$y,dt(t2,df=100)))
plot(d,xlab="$t$-statistic",ylim=ylim,main="")
lines(t2,dt(t2,df=100),col=1,lty=2)
legend("topleft",c("Empirical Distribution","Student-$t$ Distribution"),
lty=1:2,
col=c(1,1),
bty="n")
install.packages(c("broom", "chron", "class", "colorspace", "dplyr", "fansi", "ff", "forcats", "fs", "gargle", "kernlab", "knitr", "lubridate", "markdown", "MASS", "nlme", "Rcpp", "rmarkdown", "Rmpfr", "sass", "spatial", "tidyr", "tseries", "utf8", "vctrs", "vroom", "xfun", "yaml"))
library("quantmod")
getSymbols(c("CPALTT01USQ659N","LRUN64TTUSQ156N","A191RO1Q156NBEA","A191RL1Q225SBEA"),src="FRED")
X = cbind(CPALTT01USQ659N,LRUN64TTUSQ156N,A191RO1Q156NBEA)
X = na.omit(X)
df = data.frame(X)
colnames(df) = c("Inflation","Unemployment","Growth")
date = as.Date(index(X))
k = ncol(df)
for (i in 1:k) {
df[,i] = scale(df[,i],TRUE,TRUE)
}
par(mfrow=c(k,1))
for (i in 1:k) {
plot(date,df[,i],type="l",xaxs="i",las=1,main=colnames(df)[i],col="steelblue4")
grid()
abline(h=0,lty=2)
}
par(mfrow=c(k,1))
plot(df$Unemployment,df$Inflation,las=1,col="steelblue4",main="Philips Curve")
abline(h=0,v=0,lty=2)
plot(df$Inflation,df$Growth,las=1,col="steelblue4",main="Inflation & Growth")
abline(h=0,v=0,lty=2)
plot(df$Unemployment,df$Growth,las=1,col="steelblue4",main="Okun's Law")
abline(h=0,v=0,lty=2)
### OKUNS LAW
par(mfrow=c(1,1))
plot(df$Unemployment,df$Growth,las=1,col="steelblue4")
abline(h=0,v=0,lty=2)
lm1 = lm(df$Growth~df$Unemployment,data=df)
summary(lm1)
# PREDICTED CONFIDENCE INTERVAL
pred1 = predict(lm1, interval = "prediction", level=0.9) # prediction interval
lines(df$Unemployment,pred1[,1],col="brown3")
lines(df$Unemployment,pred1[,2],col="brown3")
lines(df$Unemployment,pred1[,3],col="brown3")
### INFLATION & GROWTH
Df = df[-1,]
inf = embed(df$Inflation,2)
Df$dINFL = inf[,1]-inf[,2]
par(mfrow=c(1,1))
plot(Df$Growth,Df$dINFL,las=1,col="steelblue4")
abline(h=0)
lm1 = lm(Df$dINFL~Df$Growth)
summary(lm1)
# PREDICTED CONFIDENCE INTERVAL
pred1 = predict(lm1, interval = "prediction", level=0.9) # prediction interval
lines(Df$Growth,pred1[,1],col="brown3")
lines(Df$Growth,pred1[,2],col="brown3")
lines(Df$Growth,pred1[,3],col="brown3")
### PHILIPS CURVE
par(mfrow=c(1,1))
plot(Df$Unemployment,Df$dINFL,las=1,col="steelblue4")
abline(h=0)
lm1 = lm(Df$dINFL~Df$Unemployment)
summary(lm1)
# PREDICTED CONFIDENCE INTERVAL
pred1 = predict(lm1, interval = "prediction",level=0.9)
lines(Df$Unemployment,c(pred1[,1]),col="brown3")
lines(Df$Unemployment,c(pred1[,2]),col="brown3")
lines(Df$Unemployment,c(pred1[,3]),col="brown3")
### FORECASTING VAR
library("vars")
install.packages("vars")
### FORECASTING VAR
library("vars")
df = df[,c(3,2,1)]
var1 = VAR(df,p=1)
summary(var1)
fit = fitted(var1)
plot(date,df$Inflation,type="l",xaxs="i",las=1,col="steelblue4",main="Inflation")
lines(date[-1],fit[,1],col="brown3",lty=2)
grid()
abline(h=0,lty=2)
plot(date,df$Unemployment,type="l",xaxs="i",las=1,col="steelblue4",main="Unemployment")
lines(date[-1],fit[,2],col="brown3",lty=2)
grid()
abline(h=0,lty=2)
plot(date,df$Growth,type="l",xaxs="i",las=1,col="steelblue4",main="GDP Growth")
lines(date[-1],fit[,3],col="brown3",lty=2)
grid()
abline(h=0,lty=2)
plot(irf(var1, ortho=T,n.ahead=20,cumulative=F,runs=300,ci=0.9),col=1,ylim=c(-0.4,0.5),xaxs="i")
### FORECAST
n = 200
nfore = 10
tot = n+nfore
pred1 = predict(var1, n.ahead = nfore, ci = 0.5, newdata=df[1:n,])
plot(pred1,xaxs="i",col="steelblue4")
plot(date,df$Growth,type="l",xaxs="i",las=1,col="steelblue4",main="GDP Growth Forecast")
grid()
abline(h=0,lty=2)
lines(date[1:tot],c(df$Growth[1:n],pred1$fcst$Growth[,1]),col="steelblue2",lty=2)
lines(date[1:tot],c(df$Growth[1:n],pred1$fcst$Growth[,2]),col="steelblue2",lty=2)
lines(date[1:tot],c(df$Growth[1:n],pred1$fcst$Growth[,3]),col="steelblue2",lty=2)
lines(date,df$Growth,col="steelblue4")
# Federal Funds Rate: In the United States, the federal funds rate is the interest rate at which depository institutions (banks and credit unions) lend reserve balances to other depository institutions overnight, on an uncollateralized basis.
# LIBOR: The London Interbank Offered Rate is the average of interest rates estimated by each of the leading banks in London that it would be charged were it to borrow from other banks
# In normal times they are not differing a lot. The spread represents the risk in the financial market.
getSymbols(c("DFF","USDONTD156N"),src="FRED")
X = cbind(DFF,USDONTD156N)
library("quantmod")
# Federal Funds Rate: In the United States, the federal funds rate is the interest rate at which depository institutions (banks and credit unions) lend reserve balances to other depository institutions overnight, on an uncollateralized basis.
# LIBOR: The London Interbank Offered Rate is the average of interest rates estimated by each of the leading banks in London that it would be charged were it to borrow from other banks
# In normal times they are not differing a lot. The spread represents the risk in the financial market.
getSymbols(c("DFF","USDONTD156N"),src="FRED")
PV = 1000 # Initial investment
days = 25 # investment period
library("MASS")
data(SP500)
ret = SP500/100 # daily returns
plot(density(ret),las=1,xaxs="i",main="Distribution of S&P500 Returns")
# Historical VaR
percentile = 0.05
VaR.hist = quantile(ret,c(percentile)); VaR.hist # 1%, 5% quantile of worst events
VaR.hist = 1+VaR.hist[1]*sqrt(1:days)
# The Variance-Covariance Method
mu = mean(ret); mu
sd = sd(ret); sd
x = seq(-5,5,0.001)
fx = dnorm(x,mu,sd)
plot(density(ret),type="l",las=1,xaxs="i",xlab="",ylab="",main="Var-Cov Method")
lines(x,fx,col="steelblue4")
VaR.VC = qnorm(c(percentile),mu,sd)
VaR.VC = 1+VaR.VC[1]*sqrt(1:days)
# Monte Carlo Simulation (Preferred)
iter = 5000 # repetition
pv = NULL
for (i in 1:iter) {
pv1 = cumprod(1+rnorm(days,mu,sd))
pv = rbind(pv,pv1)
}
MEAN = apply(pv,2,mean); MEAN
plot(MEAN,type="l",ylim=c(2-max(abs(pv)),max(abs(pv))),xaxs="i",las=1,xlab="",ylab="",main="Monte Carlo Simulation")
for (i in 1:iter) {
lines(pv[i,],col=1)
}
lines(VaR.hist,col="steelblue3",lwd=2)
lines(VaR.VC,col="steelblue1",lty=2,lwd=2)
lines(apply(pv,2,quantile,percentile),col="gold4",lty=2,lwd=2)
### Monte Carlo Simulation using Student's t (Normality Problem)
library("moments")
jarque.test(ret) # returns are not normal so why should we model with normal
fit.df = fitdistr(ret,"t") # accounts for fat tails
est.df = fit.df$estimate[3]
pvt = NULL
for (i in 1:iter) {
pv1 = cumprod(1+mu+sd*rt(days,df=est.df))
pvt = rbind(pvt,pv1)
}
MEAN = apply(pvt,2,mean); MEAN
plot(MEAN,type="l",ylim=c(2-max(abs(pv)),max(abs(pv))),xaxs="i",las=1,xlab="",ylab="",main="Monte Carlo Simulation")
for (i in 1:iter) {
lines(pvt[i,],col=1)
}
lines(VaR.hist,col="steelblue3",lwd=2)
lines(VaR.VC,col="steelblue1",lty=2,lwd=2)
lines(apply(pv,2,quantile,percentile),col="gold4",lty=2,lwd=2)
lines(apply(pvt,2,quantile,percentile),col="brown4",lty=2,lwd=2)
### MONTE CARLO FORECAST
library("quantmod")
getSymbols(c("^GSPC"))
stock = GSPC
#getSymbols(c("^GDAXI"))
#stock = GDAXI
#getSymbols(c("GE"))
#stock = GE
Price = as.numeric(na.omit(stock[,1]))
plot(Price,type="l",xaxs="i",las=1,xlab="",ylab="",main="")
days = 300
space = 1000
price1 = Price[(length(Price)-space):length(Price)]
price = price1[1:(length(price1)-days)]
ret = diff(log(price1))
SD = sd(ret); SD
mu = mean(ret); mu
iter = 1000
pv = NULL
for (i in 1:iter) {
pv1 = price[length(price)]*cumprod(1+rnorm(days,mu,SD))
pv = rbind(pv,pv1)
}
MEAN = apply(pv,2,mean)
QL = apply(pv,2,quantile,0.1)
QU = apply(pv,2,quantile,0.9)
QVaR = apply(pv,2,quantile,0.01)
plot(price1,type="l",xaxs="i",las=1,ylim=c(min(price1,pv),max(price1,pv)),xlab="",ylab="")
for (i in 1:iter) {
lines(c(price,pv[i,]),col="grey40")
}
grid()
lines(c(price,MEAN),col="steelblue1")
lines(c(price,QU),col="steelblue1",lty=2)
lines(c(price,QL),col="steelblue1",lty=2)
lines(c(price,QVaR),col="steelblue1",lty=2,lwd=2)
lines(c(price1),lwd=2)
getSymbols(c("^GDAXI"))
stock = GDAXI
Price = as.numeric(na.omit(stock[,1]))
plot(Price,type="l",xaxs="i",las=1,xlab="",ylab="",main="")
days = 300
space = 500
price1 = Price[(length(Price)-space):length(Price)]
price = price1[1:(length(price1)-days)]
ret = diff(log(price))
q()
setwd("C:/Users/Administrator/Documents/Github/cayman")
blogdown::new_site(theme = "lorenzwalthert/cayman-hugo-theme", theme_example = T)
blogdown::serve_site()
